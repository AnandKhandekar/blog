{
  
    
        "post0": {
            "title": "Sampling ,Translation and Scaling of a Univariate Gaussian",
            "content": "Introduction . This is the third blog post in the series to understand and visualize Multivariate Gaussian probability distributions. . Usually, we are given a predefined value of $mean$ $&#39; mu&#39;$ and the $standard$ $deviation$ $&#39; sigma&#39;$ of a Normal distribution. For a random variable $Z$ we then know the pdf of the Normal diistribution to which it belongs to as follows : $$Z sim mathcal{N}(0,1)$$ $$f(z) = frac1{ sqrt{2 pi sigma^2}}{exp}(^ frac{Z- mu}{ sigma})$$ We can simply substitute various values of Z to obtain the single valued output of the pdf . Sampling . The process of sampling for a univariate Normal distribution must be clearly understood in order to draw parallels with it when multi variate distributions are discussed. Here, the mean and the variance of the normal distribution are single numbers, which will be replaced by vectorsa and square matrices respectively while dealing with mutli variate Normal distribution. . We will assume that we have a gaussian distribution that we need to sample from. Now we just have the mean and the variance and we will PRODUCE data. . For us to do so, we will assume that we have a mechanism that produces uniform samples between 0 and 1 of EQUAL probability. All computer programming languages have this in buit psudo random number generator. . We will also assume that we can compute the CUMULATIVE of the Gaussian. Cumulative is what we get if we start suming up the area below the Gaussian from the left as shown in the plot. The inflexion point is at the mean. The area to the left is equal to the area in the right. The asymptote of the curve is 1 since the area under the pdf is always 1. . Now we draw a random number from the uniform distribution between 0 and 1. We project this number horizontally on the graph of the cdf and from there we project the point vertically down on the X- axis to retrieve a SAMPLE. This is how a computer samples. This process is called the Inverse Cumulative mapping. If we do this often we will get more samples around the mean. . Specifically the computer generates samples from ZERO mean and UNIT variance. $Z sim mathcal{N}(0,1)$ . # defining the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd %matplotlib inline . . def univariate_normal(x, mean, variance): &quot;&quot;&quot;pdf of the univariate normal distribution.&quot;&quot;&quot; return ((1. / np.sqrt(2 * np.pi * variance)) * np.exp(-(x - mean)**2 / (2 * variance))) . . # No of Data points N = 1000 # initializing random values data = np.random.randn(N) # getting data of the histogram count, bins_count = np.histogram(data, bins=18) # finding the PDF of the histogram using count values pdf = count / sum(count) # using numpy np.cumsum to calculate the CDF cdf = np.cumsum(pdf) fig, ax = plt.subplots() # plotting PDF and CDF plt.subplot(221) #plt.plot(bins_count[1:], pdf, color=&quot;red&quot;, label=&quot;PDF&quot;) plt.plot(bins_count[1:], cdf, label=&quot;CDF&quot;) plt.axhline(y = 0.8,xmin =0.62,xmax=0.95,color = &#39;g&#39;, linestyle = &#39;--&#39;) plt.axvline(x = 0.8,ymin =0 ,ymax=0.78,color = &#39;g&#39;, linestyle = &#39;--&#39;) plt.legend() plt.subplot(222) plt.xlim(-2,2) plt.ylim(0,1) plt.axhline(y=0.8, xmin = 0, xmax=0.75,color =&#39;g&#39;,linestyle=&#39;--&#39;) plt.axvline(x=0,color =&#39;k&#39;,linestyle=&#39;-&#39;) plt.axvline(x = 1,color = &#39;g&#39;, linestyle = &#39;-&#39;) plt.subplot(223) Z = np.linspace(-np.pi, np.pi,300) mean, variance = 0 ,1 plt.plot(Z , univariate_normal(Z,mean,variance)) plt.axvline( x=0.8, ymin=0, ymax=0.7,color = &#39;g&#39;, linestyle = &#39;--&#39;) circle1 = plt.Circle((0.8, -0.04), 0.05, color=&#39;r&#39;) ax.add_patch(circle1) . . &lt;matplotlib.patches.Circle at 0x7f8d3b49ec10&gt; . Essential Statisitcs of Univariate Normal . Note : this section can be skipped without any loss in continuity. We will now refresh some basic concepts in Probability. We will derive the equation for the MEAN and the VARIANCE of te univariate normal distribution. $$x sim mathcal{N}(0,1)$$ $$f(x) = frac1{ sqrt{2 pi sigma^2}}{exp}(^ frac{x- mu}{ sigma})$$ . Area below the pdf is always . $$ int_{- infty}^{ infty}f(x) ,dx = 1 $$ . Expectation of the Normal r.v is equal to the mean . $$ mathbb{E}(X)= mu $$ . Variance of the Normal r.v. . refer this link for the proof $$Var(X) = sigma^2$$ . Translation ( Adding a consant to the Normal distribution ) . fig, ax = plt.subplots() Z = np.linspace(-2*np.pi, 3* np.pi,300) mean, variance = 0 ,1 k=2 plt.plot(Z , univariate_normal(Z,mean,variance)) plt.axvline( x=variance, ymin=0, ymax=0.6,color = &#39;g&#39;, linestyle = &#39;--&#39;) plt.axvline( x=-variance, ymin=0, ymax=0.6,color = &#39;g&#39;, linestyle = &#39;--&#39;) plt.plot(Z , univariate_normal(Z,mean+k,variance)) plt.axvline( x=variance+k, ymin=0, ymax=0.5,color = &#39;y&#39;, linestyle = &#39;--&#39;) plt.axhline(y=0.4, xmin = 0.4, xmax=0.52,color =&#39;k&#39;,linestyle=&#39;-&#39;) #plt.axvline( x=-variance-k, ymin=0, ymax=0.6,color = &#39;y&#39;, linestyle = &#39;--&#39;) plt.xlim(-2*np.pi, 3*np.pi) plt.title(&quot;Translation by k n$ mu_x = mu_z + k$ n $ sigma_x = sigma_z$&quot;) . . Text(0.5, 1.0, &#39;Translation by k n$ mu_x = mu_z + k$ n $ sigma_x = sigma_z$&#39;) . Scaling of a Normal Distribution . Now consider the original r.v $x$ sampled from a normal distributiona again and let $k$ and $b$ be constant numbers such that $Z = k ;X+ ;b$. In generral, if $X sim mathcal{N}( mu_x, sigma_x^2)$ and if $Y = k *X + b$, then we can prove that $Y sim mathcal{N}( mu_y, sigma_y^2)$ where $ mu_y = k* mu_x + b$ and $ sigma_y^2 = k^2 sigma_x^2$ . Proof: . $$Z sim mathcal{N}(0,1)$$original r.v. from pseudo number generator. $ mu_z = 0$ and $ sigma_z = 1$ $$X = sim mathcal{N}( mu_x, sigma_x^2)$$ $$ therefore X = sigma_x ;Z + mu_x$$ Thus $$Y = k ;X + b$$ $$Y = k ; ( sigma_x ;Z + mu_x) + b$$ $$Y = (a ; sigma_x)Z ;+ ;(a mu_x ;+ ;b)$$ . where, $$ mu_y = a mu_x ;+ ;b $$ and $$Var(Y) = a^2 ; sigma_x^2 $$ . Why standard normal samples multiplied by sd are samples from a normal dist with that sd ? .",
            "url": "https://anandkhandekar.github.io/blog/jupyter/univariate/normal/standard%20deviation/variance/2021/05/05/SamplingTranslationScaling.html",
            "relUrl": "/jupyter/univariate/normal/standard%20deviation/variance/2021/05/05/SamplingTranslationScaling.html",
            "date": " • May 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Visual Representation of a Bivariate Gaussian",
            "content": "Dependencies . %matplotlib inline import sys import numpy as np import matplotlib import matplotlib.pyplot as plt from matplotlib import cm # Colormaps import matplotlib.gridspec as gridspec from mpl_toolkits.axes_grid1 import make_axes_locatable from matplotlib import cm from mpl_toolkits.mplot3d import Axes3D import seaborn as sns sns.set_style(&#39;darkgrid&#39;) np.random.seed(42) . . MultiVariate Normal distribution . Real world datasets are seldom univariate. Infact they are often multi variate with large dimensions. Each of these dimensions, also referred to as features, ( columns in a spread sheet) may or maynot be corellated to each other. . In particular, we are interested in the multivariate case of this distribution, where each random variable is distributed normally and their joint distribution is also Gaussian. The multivariate Gaussian distribution is defined by a mean vector $ mu$ and a covariance matrix $ Sigma$. . The mean vector $ mu$ describes the expected value of the distribution. Each of its components describes the mean of the corresponding dimension. $ Sigma$ models the variance along each dimension and determines how the different random variables are correlated. The covariance matrix is always symmetric and positive semi-definite. The diagonal of $ Sigma$ consists of the variance $ sigma_i^2$ of the $i$-th random variable. And the off-diagonal elements $ sigma_{ij}$ describe the correlation between the $i$-th and the $j$-th random variable. ​ $$X = begin{bmatrix} X_1 X_2 . . X_n end{bmatrix} sim mathcal{N}( mathbf{ mu}, Sigma) $$ . Wee say that $X$ follows a normal distribution. The covariance $ Sigma$ describs the shape of the distribution. It is defined in terms of the expected value $ mathbb{E}$ : $$ Sigma = Cov( X_i, X_j) = mathbb{E}[ ( X_i- mu_i) (X_i - mu_j)^T]$$ . ​ . Let us consider a multi variate normmal random variable $x$ of dimensionality $d$ i.e $d$ numberof features or columns. Then the joint probability densit is given by : $$p( mathbf{x} mid mathbf{ mu}, Sigma) = frac{1}{ sqrt{(2 pi)^d lvert Sigma rvert}} exp{ left( - frac{1}{2}( mathbf{x} - mathbf{ mu})^T Sigma^{-1} ( mathbf{x} - mathbf{ mu}) right)}$$ . where $ textbf{x}$ a random sized vector of size $d$, $ textbf{$ mu$}$ is the mean vector, $ Sigma$ is the ( symmetric , positive definite ) covariance matrix ( of size $d times d$ ), and $ lvert Sigma rvert$ its determinant. . We denote the multivariate nornal distribution as : $$ mathcal{N}( mathbf{ mu}, Sigma)$$ The mean vector $ mathbf{ mu}$, is the expected value of the distribution; and the covariance matrix $ Sigma$, which measures how dependent any two random varibales are and how they change with each other. . custom defined multivariate normal distribution function. . this CODE can be skipped and w can always fall back on Numpy or Scipy who provide in built functions to do the same. But then, who does that ? . def multivariate_normal(x, d, mean, covariance): x_m = x - mean return (1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) / 2)) . . Bivariate normal distribution . Let us consider a r.v with two dimensions $x_1$ and $x_2$ with the covariance between them set to $0$ so that the two are independent : Also, for the sake of siplicity, let us assume a $0$ mean along both the dimensions. $$ mathcal{N} left( begin{bmatrix} 0 0 end{bmatrix}, begin{bmatrix} 1 &amp; 0 0 &amp; 1 end{bmatrix} right)$$ . he figure on the right is a bivariate distribution with the covariance between $x_1$ and $x_2$ set to be other than $0$ so that both the variables are correlated. Increasing $x_1$ will increase the probability that $x_2$ will also increase. $$ mathcal{N} left( begin{bmatrix} 0 1 end{bmatrix}, begin{bmatrix} 1 &amp; 0.8 0.8 &amp; 1 end{bmatrix} right)$$ . Helper function to generate density surface . def generate_surface(mean, covariance, d): nb_of_x = 100 # grid size x1s = np.linspace(-5, 5, num=nb_of_x) x2s = np.linspace(-5, 5, num=nb_of_x) x1, x2 = np.meshgrid(x1s, x2s) # Generate grid pdf = np.zeros((nb_of_x, nb_of_x)) # Fill the cost matrix for each combination of weights for i in range(nb_of_x): for j in range(nb_of_x): pdf[i,j] = multivariate_normal( np.matrix([[x1[i,j]], [x2[i,j]]]), d, mean, covariance) return x1, x2, pdf # x1, x2, pdf(x1,x2) . . # subplot fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,6)) d = 2 # number of dimensions # Plot of independent Normals bivariate_mean = np.matrix([[0.], [0.]]) # Mean bivariate_covariance = np.matrix([ [1., 0.], [0., 1.]]) # Covariance x1, x2, p = generate_surface( bivariate_mean, bivariate_covariance, d) # Plot bivariate distribution con = ax1.contourf(x1, x2, p, 100, cmap=cm.viridis) ax1.set_xlabel(&#39;$x_1$&#39;, fontsize=13) ax1.set_ylabel(&#39;$x_2$&#39;, fontsize=13) ax1.axis([-2.5, 2.5, -2.5, 2.5]) ax1.set_aspect(&#39;equal&#39;) ax1.set_title(&#39;Independent variables&#39;, fontsize=12) # Plot of correlated Normals bivariate_mean = np.matrix([[0.], [1.]]) # Mean bivariate_covariance = np.matrix([ [1., 0.8], [0.8, 1.]]) # Covariance x1, x2, p = generate_surface( bivariate_mean, bivariate_covariance, d) # Plot bivariate distribution con = ax2.contourf(x1, x2, p, 100, cmap=cm.viridis) ax2.set_xlabel(&#39;$x_1$&#39;, fontsize=13) ax2.set_ylabel(&#39;$x_2$&#39;, fontsize=13) ax2.axis([-2.5, 2.5, -1.5, 3.5]) ax2.set_aspect(&#39;equal&#39;) ax2.set_title(&#39;Correlated variables&#39;, fontsize=12) # Add colorbar and title fig.subplots_adjust(right=0.8) cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7]) cbar = fig.colorbar(con, cax=cbar_ax) cbar.ax.set_ylabel(&#39;$p(x_1, x_2)$&#39;, fontsize=13) plt.suptitle(&quot;Bivariate normal distributions &quot;, fontsize=13, y=0.95) plt.show() . . Mean vector and Covariance Matrices . The Gaussian on the LHS $$ mathcal{N} left( begin{bmatrix} 0 1 end{bmatrix}, begin{bmatrix} 1 &amp; 0 0&amp; 1 end{bmatrix} right)$$ . The gaussian on the RHS $$ mathcal{N} left( begin{bmatrix} 0 1 end{bmatrix}, begin{bmatrix} 1 &amp; 0.8 0.8 &amp; 1 end{bmatrix} right)$$ . Surface plot in Matplot Lib . # Our 2-dimensional distribution will be over variables X and Y N = 60 X = np.linspace(-3, 3, N) Y = np.linspace(-3, 4, N) X, Y = np.meshgrid(X, Y) # Mean vector and covariance matrix mu = np.array([0., 1.]) Sigma = np.array([[ 1. , -0.5], [-0.5, 1.5]]) # Pack X and Y into a single 3-dimensional array pos = np.empty(X.shape + (2,)) pos[:, :, 0] = X pos[:, :, 1] = Y def multivariate_gaussian(pos, mu, Sigma): &quot;&quot;&quot;Return the multivariate Gaussian distribution on array pos. pos is an array constructed by packing the meshed arrays of variables x_1, x_2, x_3, ..., x_k into its _last_ dimension. &quot;&quot;&quot; n = mu.shape[0] Sigma_det = np.linalg.det(Sigma) Sigma_inv = np.linalg.inv(Sigma) N = np.sqrt((2*np.pi)**n * Sigma_det) # This einsum call calculates (x-mu)T.Sigma-1.(x-mu) in a vectorized # way across all the input variables. fac = np.einsum(&#39;...k,kl,...l-&gt;...&#39;, pos-mu, Sigma_inv, pos-mu) return np.exp(-fac / 2) / N # The distribution on the variables X, Y packed into pos. Z = multivariate_gaussian(pos, mu, Sigma) # Create a surface plot and projected filled contour plot under it. fig = plt.figure() ax = fig.gca(projection=&#39;3d&#39;) ax.plot_surface(X, Y, Z, rstride=3, cstride=3, linewidth=1, antialiased=True, cmap=cm.viridis) cset = ax.contourf(X, Y, Z, zdir=&#39;z&#39;, offset=-0.15, cmap=cm.viridis) # Adjust the limits, ticks and view angle ax.set_zlim(-0.15,0.2) ax.set_zticks(np.linspace(0,0.2,5)) ax.view_init(27, -21) plt.show() . . Visualize using GEOGEBRA . This is an open source tool that I have utilized in order to visualize the 2D Normal Distribution. Move the sliders available to change the values of the correlation, mean and the variances to see the effect on the shape. The z dimension depicts the 2D distribution. . Anand Khandekar on Geogebra .",
            "url": "https://anandkhandekar.github.io/blog/bivariate/normal/mean%20vector/covariance/geogebra/2021/05/05/BivariateNormaldistribution.html",
            "relUrl": "/bivariate/normal/mean%20vector/covariance/geogebra/2021/05/05/BivariateNormaldistribution.html",
            "date": " • May 5, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Univariate Normal(Interactive plots - MatPlotLib and Streamlit )",
            "content": "Streamlit and MatPlotLib Animation . Streamlit is a library built on Python which helps create deployable code outputs. It is a visualisation TOOL that proves to be highly effective for technical presentations. . | MatPlotLib Animation is a class which can be ussed to create inline interactive plots in jupyter notebooks. . | . Univariate animation with MatPlotLib . These are the dependencies needed which include Seaborn for embedding a dark background in the plots. . # Imports %matplotlib inline import sys import numpy as np import matplotlib import matplotlib.pyplot as plt from matplotlib import cm # Colormaps import matplotlib.gridspec as gridspec from mpl_toolkits.axes_grid1 import make_axes_locatable import seaborn as sns sns.set_style(&#39;darkgrid&#39;) np.random.seed(42) . . customized univariate function . Instead of importing this fucntion from Numpy or Scipy, we have created out own function which simply translates the equation and returns the single value. . Create a LIST of Variance . To animate the plot, we need an animate function, which generates a random set of numbers and updates the widths of the Normal pdf functions. Here, the mean value is purposefully kept constant at zero. . As the animation frames begin to unroll, a clear increment in the variance LIST is obserrved and are also displayed in the title. Calling update() will define animate function working with supplied univariate_normal() function, all this is used to setup FuncAnimation. . x = np.linspace(-np.pi, np.pi,200) # range of x define between -pi to +pi mean = 0 variance = [0.05, 0.75,2.0] # defined a LIST . . Custom defined Normal pdf function . def univariate_normal(x, mean, variance): &quot;&quot;&quot;pdf of the univariate normal distribution.&quot;&quot;&quot; return ((1. / np.sqrt(2 * np.pi * variance)) * np.exp(-(x - mean)**2 / (2 * variance))) . . Using simple FOR loops to iterate . for loops are an easier way out to visualise multiple plots with varying VARIANCE, but have a limitation in that the plots can become too small if the list has many items. Else subplot() are to be used to display a grid. In any case all these are STATIC graphs. . FuncAnimation() in turn helps one visualize the actual change in the variance dynaically . plt.figure(figsize=(5,3)) for i, var in enumerate(variance): plt.subplot(3,1,i+1) plt.plot(x,univariate_normal(x, mean, var)) plt.show() . . matplot lib animation below here . x = np.linspace(0.,1.,500) # 500 points evenly spaced ovr [0,1] mu = np.zeros((500)) . . fig,ax = plt.subplots() from matplotlib.animation import FuncAnimation from matplotlib import rc import seaborn as sns sns.set_style(&#39;darkgrid&#39;) var = [0.05, 0.1, 0.25, 0.5, 1., 2., 4.] x = np.linspace(-2.,2.,500) # 500 points evenly spaced ovr [0,1] mu = np.zeros((500)) def update(iterations): ax.cla() k = var[iterations] for i in range(20): ax.plot(x,univariate_normal(x, mean, k),color=&#39;b&#39;, alpha=0.2) ax.set_title(&quot;$Univariate-Normal$ n variance = %s &quot; %var[iterations]); ax.set_ylim((0,2)) num_iterations = len(var) anim = FuncAnimation(fig, update, frames = np.arange(0,num_iterations-1,1), interval = 250) plt.close() rc(&#39;animation&#39;,html=&#39;jshtml&#39;) anim . . &lt;/input&gt; Once Loop Reflect",
            "url": "https://anandkhandekar.github.io/blog/jupyter/univariate/normal/animation/streamlit/2021/05/03/UnivariateInteractive.html",
            "relUrl": "/jupyter/univariate/normal/animation/streamlit/2021/05/03/UnivariateInteractive.html",
            "date": " • May 3, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Univariate Normal Distribution ( 1D Gaussian )",
            "content": "This post will introduce univariate normal distribution. It intends to explain how to represent, visualize and sample from this distribution. . This post assumes basic knowledge of probability theory, probability distriutions and linear algebra. . The normal distribution , also known as the Gaussian distribution, is so called because its based on the Gaussian function . This distribution is defined by two parameters: the mean $ mu$, which is the expected value of the distribution, and the standard deviation $ sigma$, which corresponds to the expected deviation from the mean. The square of the standard deviation is typically referred to as the variance $ sigma^{2}$. We denote this distribution as: $$ mathcal{N}( mu, sigma^2)$$ . Given this mean and the variance we can calculate the probability density fucntion (pdf) of the normal distribution with the normalised Gaussian function. For a random variable $x$ the density is given by : $$p(x mid mu, sigma) = frac{1}{ sqrt{2 pi sigma^2}} exp{ left( - frac{(x - mu)^2}{2 sigma^2} right)}$$ . Thi distribution is called Univariate because it consists of only one random variable. . basic dependencies imported . # Imports %matplotlib inline import sys import numpy as np import matplotlib import matplotlib.pyplot as plt from matplotlib import cm # Colormaps import matplotlib.gridspec as gridspec from mpl_toolkits.axes_grid1 import make_axes_locatable import seaborn as sns sns.set_style(&#39;darkgrid&#39;) np.random.seed(42) . . customized univariate function . Instead of importing this fucntionfrom nummpy or scipy, we have created out own function which simply translates the equation and returns the single value. . def univariate_normal(x, mean, variance): &quot;&quot;&quot;pdf of the univariate normal distribution.&quot;&quot;&quot; return ((1. / np.sqrt(2 * np.pi * variance)) * np.exp(-(x - mean)**2 / (2 * variance))) . . Plot different Univariate Normals . x = np.linspace(-3, 5, num=150) fig = plt.figure(figsize=(10, 6)) plt.plot( x, univariate_normal(x, mean=0, variance=1), label=&quot;$ mathcal{N}(0, 1)$&quot;) plt.plot( x, univariate_normal(x, mean=2, variance=3), label=&quot;$ mathcal{N}(2, 3)$&quot;) plt.plot( x, univariate_normal(x, mean=0, variance=0.2), label=&quot;$ mathcal{N}(0, 0.2)$&quot;) plt.xlabel(&#39;$x$&#39;, fontsize=13) plt.ylabel(&#39;density: $p(x)$&#39;, fontsize=13) plt.title(&#39;Univariate normal distributions&#39;) plt.ylim([0, 1]) plt.xlim([-3, 5]) plt.legend(loc=1) fig.subplots_adjust(bottom=0.15) plt.show() . . Normal distribution PDF with different standard deviations . Let’s plot the probability distribution functions of a normal distribution where the mean has different standard deviations. . from scipy.stats import norm import numpy as np import matplotlib.pyplot as plt . . fig, ax = plt.subplots(figsize=(10, 6)) #fig = plt.figure(figsize=(10, 6)) x = np.linspace(-10,10,100) stdvs = [1.0, 2.0, 3.0, 4.0] for s in stdvs: ax.plot(x, norm.pdf(x,scale=s), label=&#39;stdv=%.1f&#39; % s) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;pdf(x)&#39;) ax.set_title(&#39;Normal Distribution&#39;) ax.legend(loc=&#39;best&#39;, frameon=True) ax.set_ylim(0,0.45) . . (0.0, 0.45) . Normal distribution PDF with different means . Let’s plot probability distribution functions of normal distribution where the standard deviation is 1 and different means. . fig, ax = plt.subplots(figsize=(10, 6)) x = np.linspace(-10,10,100) means = [0.0, 1.0, 2.0, 5.0] for mean in means: ax.plot(x, norm.pdf(x,loc=mean), label=&#39;mean=%.1f&#39; % mean) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;pdf(x)&#39;) ax.set_title(&#39;Normal Distribution&#39;) ax.legend(loc=&#39;best&#39;, frameon=True) ax.set_ylim(0,0.45) . . (0.0, 0.45) . A cumulative normal distribution function . The cumulative distribution function of a random variable X, evaluated at x, is the probability that X will take a value less than or equal to x. Since the normal distribution is a continuous distribution, the shaded area of the curve represents the probability that X is less or equal than x. . $$P(X leq x)=F(x)= int limits _{- infty} ^{x}f(t)dt text{, where }x in mathbb{R}$$ . fig, ax = plt.subplots(figsize=(10,6)) # for distribution curve x= np.arange(-4,4,0.001) ax.plot(x, norm.pdf(x)) ax.set_title(&quot;Cumulative normal distribution&quot;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;pdf(x)&#39;) ax.grid(True) # for fill_between px=np.arange(-4,1,0.01) ax.set_ylim(0,0.5) ax.fill_between(px,norm.pdf(px),alpha=0.5, color=&#39;g&#39;) # for text ax.text(-1,0.1,&quot;cdf(x)&quot;, fontsize=20) plt.show() . .",
            "url": "https://anandkhandekar.github.io/blog/jupyter/univariate/normal/2021/05/02/UnivariateGaussian.html",
            "relUrl": "/jupyter/univariate/normal/2021/05/02/UnivariateGaussian.html",
            "date": " • May 2, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://anandkhandekar.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://anandkhandekar.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Anand Khandekar&lt;Founder,Director of the_Running_Professor Anand is a passionate academic for 20+ years, diving into Engg. Math, Mechanics, Fluid Mechanics,Theory of Machines and Vibrations. A Masters degree in CAD/CAM further pushed him into the iOT domain. Since last 3 years, Anand is building TRP, an A.I. company with the sole intention of providing solutions to all. .",
          "url": "https://anandkhandekar.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://anandkhandekar.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}